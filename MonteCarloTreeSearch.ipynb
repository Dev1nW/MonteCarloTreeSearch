{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "import math\n",
    "from copy import deepcopy\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UCB1(v, n, parent_n):\n",
    "    return v/n + 2*math.sqrt(math.log(parent_n)/n)\n",
    "\n",
    "class MonteCarloTreeSearch():\n",
    "    def __init__(self, max_iterations=1000, env=\"ALE/Breakout-v5\"):\n",
    "        # Set up the environment \n",
    "        self.env = gym.make(env)\n",
    "\n",
    "        # Start the Environment\n",
    "        initial_state = self.env.reset()\n",
    "\n",
    "        # Set the root_state to be a clone of the initial environment state\n",
    "        self.root_state = self.env.ale.cloneState()\n",
    "\n",
    "        # Create Root Node\n",
    "        self.root_node = Node(None, False, 'root', self.root_state)\n",
    "\n",
    "        # Count for naming of Nodes\n",
    "        self.counter = 1\n",
    "\n",
    "        # Total steps taken so far\n",
    "        self.iterations = 0\n",
    "\n",
    "        # Maximum number of iterations\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def start_search(self):\n",
    "        while True:\n",
    "\n",
    "            # Check if you have reached the max iterations \n",
    "            if self.iterations >= self.max_iterations:\n",
    "\n",
    "                # Return the root node\n",
    "                return self.root_node\n",
    "            \n",
    "            # Choose the next node to explore \n",
    "            next_node = self.choose_next_node(self.root_node)\n",
    "\n",
    "            # Complete random search \n",
    "            self.random_search(next_node)\n",
    "\n",
    "            if self.iterations % 20 == 1:\n",
    "                print('Explored for ' + str(self.iterations) + ' iterations')\n",
    "\n",
    "    \n",
    "    def choose_next_node(self, node):\n",
    "        # If you are at a terminal state you should end algorithm\n",
    "        if node.terminal_state == True: \n",
    "            # Edge condition for when leaf node is reached\n",
    "            return node.parent\n",
    "        \n",
    "        # Check if the node is new or if it has children already\n",
    "        elif len(node.children) < 1:\n",
    "            # If it is a new Node then get all children\n",
    "            self.get_child_nodes(node)\n",
    "\n",
    "\n",
    "        max_UCB1 = None\n",
    "        final_child = None\n",
    "\n",
    "        explored_child_count = 0\n",
    "\n",
    "        for child in node.children:\n",
    "            # If it's the first time going through the node then you take the first child as the final node\n",
    "            if node.times_visited == 0:\n",
    "                final_child = child\n",
    "                break\n",
    "\n",
    "            # If you haven't explored the child then explore it\n",
    "            if child.times_visited == 0:\n",
    "                final_child = child\n",
    "                break\n",
    "            \n",
    "            # Else use the value with the highest UCB1 Score\n",
    "            else:\n",
    "                # Calculate the UCB1 Score \n",
    "                child_UCB1 = UCB1(child.value, child.times_visited, node.times_visited)\n",
    "                explored_child_count += 1\n",
    "\n",
    "            # Initial max UCB1 \n",
    "            if max_UCB1 == None:\n",
    "                max_UCB1 = child_UCB1\n",
    "                final_child = child\n",
    "            \n",
    "            # This makes the Algorithm choose which state-action pair is the best\n",
    "            # If the current child UCB1 score is better than the best UCB1 then it is chosen\n",
    "            elif child_UCB1 > max_UCB1:\n",
    "                max_UCB1 = child_UCB1\n",
    "                final_child = child\n",
    "        \n",
    "        # If you have explored all states from the parent class explore child Node\n",
    "        if explored_child_count == len(node.children):\n",
    "            final_child = self.choose_next_node(final_child)\n",
    "\n",
    "        # Return the child to be explored \n",
    "        return final_child \n",
    "\n",
    "    def random_search(self, node):\n",
    "        # Set state to explore from\n",
    "        self.env.ale.restoreState(node.state)\n",
    "\n",
    "        done = False\n",
    "\n",
    "        final_reward = 0\n",
    "\n",
    "        # Randomly traverse until you reach a terminal state\n",
    "        while not done:\n",
    "            # Choose random action\n",
    "            action = self.env.action_space.sample()\n",
    "\n",
    "            observation, reward, done, truncated, _ = self.env.step(action)\n",
    "            \n",
    "            final_reward += reward\n",
    "\n",
    "            if done == True:\n",
    "                break\n",
    "        \n",
    "        if node.times_visited < 1:\n",
    "            node.value = final_reward\n",
    "\n",
    "        # Increase the number of times that the node has been visited \n",
    "        node.times_visited += 1\n",
    "\n",
    "        # Back Prop reward to root \n",
    "        while True:\n",
    "\n",
    "            # Since the root node is initialized to be None this will be our break condition \n",
    "            if node.parent == None:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Increase the number of times that the node has been visited \n",
    "                node.parent.times_visited += 1\n",
    "                # Add the reward for the current exploration to the parent node \n",
    "                node.parent.value += final_reward\n",
    "                # Make the parent node the current node\n",
    "                node = node.parent\n",
    "        \n",
    "        # After this you have completed one full iteration \n",
    "        self.iterations += 1 \n",
    "\n",
    "\n",
    "    # Get all children nodes for a parent (take all possible actions from the parent state)\n",
    "    def get_child_nodes(self, node):\n",
    "\n",
    "        # Go through all possible actions that can be taken in the state\n",
    "        for i in range(self.env.action_space.n):\n",
    "            \n",
    "            # Load in state informantion\n",
    "            self.env.ale.restoreState(node.state)\n",
    "\n",
    "            # Perform action\n",
    "            observation, reward, done, truncated, _ = self.env.step(i)\n",
    "\n",
    "            # Create child node \n",
    "            child_node = Node(node, done, str(self.counter), self.env.ale.cloneState())\n",
    "\n",
    "            # If there is a reward in that state add it to the value \n",
    "            child_node.value += reward\n",
    "            \n",
    "            # Append child to children list in the parent node\n",
    "            node.children.append(child_node)\n",
    "\n",
    "            # Increase counter for name \n",
    "            self.counter += 1 \n",
    "                \n",
    "class Node():\n",
    "    def __init__(self, parent=False, terminal_state=False, name=None, state=None):\n",
    "        # Is there a parent Node or not\n",
    "        self.parent = parent\n",
    "\n",
    "        # List of all children from the node\n",
    "        self.children = []\n",
    "\n",
    "        # Are you in a Terminal state or not\n",
    "        self.terminal_state = terminal_state\n",
    "\n",
    "        # The number of times that the state has been visited \n",
    "        self.times_visited = 0\n",
    "\n",
    "        # Value (reward for the Node)\n",
    "        # Should be 0 and updates after doing a rollout \n",
    "        self.value = 0\n",
    "\n",
    "        # Name for the node\n",
    "        self.node_name = name\n",
    "\n",
    "        # State for the node\n",
    "        self.state = state\n",
    "\n",
    "        return \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    root_node = MonteCarloTreeSearch()\n",
    "    root_node.start_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traverse the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "node = root_node.root_node\n",
    "\n",
    "while True:\n",
    "    print('Node ' + node.node_name +' has value: ' + str(node.value))\n",
    "    next_value = None\n",
    "    idx = 0\n",
    "\n",
    "    for child in node.children:\n",
    "        if next_value == None:\n",
    "            next_value = child.value\n",
    "            best_child = child\n",
    "            best_idx = idx\n",
    "            \n",
    "        elif child.value > next_value:\n",
    "            next_value = child.value\n",
    "            best_child = child\n",
    "            best_idx = idx\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    \n",
    "    if node.node_name == best_child.node_name:\n",
    "        break\n",
    "    \n",
    "    print('\\nBest action to take is ' + str(best_idx))\n",
    "\n",
    "    node = best_child\n",
    "\n",
    "    if node.terminal_state == True:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
